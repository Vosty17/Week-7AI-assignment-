# QUESTION 1
## Define algorithmic bias and provide two examples of how it manifests in AI systems??
Algorithmic biass is systematic and unfair discrimination that occurs when an AI system produces skewed or prejudiced outcomes due to flawed assumptions, biased training data, or design choices in the algorithm. This bias can disadvantage certain groups based on race, gender, age or other characteristics.

### Examples
#### 1. Racial bias in Facial Recognition
Many facial recognition systems have error rates for people with darker skin tones, particularly women of color, due to underrepresentation in training datasets. E.g a 2018 study found out that some commercial systems had error rates of upto 34% for darker-skinned women compared to near-perfect accuracy for lighter-skinned men.

#### 2. Gender Bias in Hiring Algorithms
AI-powered recruitment tools have been found to favor male candidates over female ones, expecially in male-dominated fields. For instance, Amazon-scrapped an AI hiring tool in 2018 because it downgraded resumes containing words like "women's" or graduates from all-women colleges.

# QUESTION 2
## Explain the difference between transparency and explainability in AI. Why are both important?
**Transparency:** Is the openness about how an AI system is developed, including its data sources, model architecture, training processes and potential limitations.

**Explainability:** Focuses on making individual AI decisions understandable to humans, often by providing clear, intuitive reasons for outputs. It addresses the "how" and "why" behind specific predictions or actions.

### Why both are important:
**Transparency** builds trust and exposes biases.
**Explainability** enables acountability and compliance (e.g GDPR).
Together, they promote ethical, fair, and user-friendly AI systems.


# QUESTION 3
## How does GDPR (General Data Protection Regulation) impact AI development in the EU?

The GDPR (General Data Protection Regulation) significantly impacts AI development in the EU by imposing strict rules to ensure privacy, fairness, and accountability. Key implications include:

### 1. Strict Rules for AI Development
Requires lawful, fair, and transparent AI systems.
Bans discriminatory or opaque decision-making (e.g., biased hiring algorithms).

### 2. Right to Explanation
Users can demand clear reasoning behind AI decisions (e.g., loan rejections).
Forces developers to use interpretable models (not just "black-box" AI).

### 3. Strong Data Privacy Protections
Limits data collection (minimization principle).
Requires user consent and allows data deletion ("right to be forgotten").

### 4. Bias & Discrimination Prevention
AI must avoid unfair bias, aligning with the EU AI Act’s stricter rules.

### 5. Privacy by Design
AI must embed safeguards (e.g., anonymization, encryption).

### 6. Heavy Compliance Burden
Developers must document AI processes and conduct risk assessments.
Violations risk huge fines (up to 4% of global revenue).


**Result:** GDPR pushes AI toward **ethical, user-friendly, and accountable** systems but increases costs and complexity for developers.


# QUESTIONS
# 2. Ethical Principles Matching
## Match the following principles to their definitions:

**A) Justice**

**B) Non-maleficence**

**C) Autonomy**

**D) Sustainability**

        1. Ensuring AI does not harm individuals or society.

        2. Respecting users’ right to control their data and decisions.

        3. Designing AI to be environmentally friendly.

        4. Fair distribution of AI benefits and risks.

# ANSWERS
# Here’s the correct matching of principles to their definitions:

**A) Justice** → Fair distribution of AI benefits and risks.

**B) Non-maleficence** → Ensuring AI does not harm individuals or society.

**C) Autonomy** → Respecting users’ right to control their data and decisions.

**D) Sustainability** → Designing AI to be environmentally friendly.